{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04ea1ece-6ae3-4d49-be75-8dbf59664ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /Users/imraanarbab/miniconda3/envs/sklearn-env/lib/python3.11/site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/imraanarbab/miniconda3/envs/sklearn-env/lib/python3.11/site-packages (from imbalanced-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/imraanarbab/miniconda3/envs/sklearn-env/lib/python3.11/site-packages (from imbalanced-learn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/imraanarbab/miniconda3/envs/sklearn-env/lib/python3.11/site-packages (from imbalanced-learn) (1.4.1.post1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/imraanarbab/miniconda3/envs/sklearn-env/lib/python3.11/site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/imraanarbab/miniconda3/envs/sklearn-env/lib/python3.11/site-packages (from imbalanced-learn) (2.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Data loaded in 0.07 seconds\n",
      "Data preprocessed in 0.11 seconds\n",
      "Class distribution before SMOTE: Counter({3: 4829, 1: 114, 0: 45, 2: 12})\n",
      "SMOTE applied.\n",
      "Class distribution after SMOTE: Counter({3: 4829, 0: 4829, 1: 4829, 2: 4829})\n",
      "Data split into training and testing sets in 0.74 seconds\n",
      "\n",
      "Classifier: Random Forest\n",
      "Accuracy: 0.9772256728778468\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       969\n",
      "           1       0.97      0.95      0.96      1009\n",
      "           2       1.00      1.00      1.00       917\n",
      "           3       0.98      0.98      0.98       969\n",
      "\n",
      "    accuracy                           0.98      3864\n",
      "   macro avg       0.98      0.98      0.98      3864\n",
      "weighted avg       0.98      0.98      0.98      3864\n",
      "\n",
      "Training Time: 25.70 seconds\n",
      "\n",
      "Classifier: Logistic Regression\n",
      "Accuracy: 0.9622153209109731\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94       969\n",
      "           1       0.98      0.96      0.97      1009\n",
      "           2       1.00      0.99      1.00       917\n",
      "           3       1.00      0.90      0.95       969\n",
      "\n",
      "    accuracy                           0.96      3864\n",
      "   macro avg       0.97      0.96      0.96      3864\n",
      "weighted avg       0.97      0.96      0.96      3864\n",
      "\n",
      "Training Time: 8.87 seconds\n",
      "\n",
      "Classifier: Support Vector Machine\n",
      "Accuracy: 0.9464285714285714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91       969\n",
      "           1       0.99      0.91      0.95      1009\n",
      "           2       1.00      0.99      0.99       917\n",
      "           3       1.00      0.89      0.94       969\n",
      "\n",
      "    accuracy                           0.95      3864\n",
      "   macro avg       0.95      0.95      0.95      3864\n",
      "weighted avg       0.95      0.95      0.95      3864\n",
      "\n",
      "Training Time: 484.50 seconds\n",
      "\n",
      "Classifier: Gradient Boosting\n",
      "Accuracy: 0.9702380952380952\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       969\n",
      "           1       0.98      0.95      0.97      1009\n",
      "           2       1.00      1.00      1.00       917\n",
      "           3       0.99      0.93      0.96       969\n",
      "\n",
      "    accuracy                           0.97      3864\n",
      "   macro avg       0.97      0.97      0.97      3864\n",
      "weighted avg       0.97      0.97      0.97      3864\n",
      "\n",
      "Training Time: 325.84 seconds\n",
      "Total time taken: 873.57 seconds\n"
     ]
    }
   ],
   "source": [
    "# Install imbalanced-learn library\n",
    "!pip install imbalanced-learn\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from collections import Counter\n",
    "\n",
    "# Measure the time taken for each step\n",
    "start_time = time.time()\n",
    "\n",
    "# Load a larger sample of the dataset\n",
    "file_path = 'retractions.csv'\n",
    "data = pd.read_csv(file_path, encoding='ISO-8859-1', nrows=5000)  # Load more rows\n",
    "print(\"Data loaded in {:.2f} seconds\".format(time.time() - start_time))\n",
    "\n",
    "# Data preprocessing\n",
    "data = data.drop(columns=['Unnamed: 20'])\n",
    "data = data.dropna(subset=['RetractionNature'])\n",
    "data = data.fillna('Unknown')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "data['RetractionNature'] = label_encoder.fit_transform(data['RetractionNature'])\n",
    "\n",
    "selected_features = ['Journal', 'Publisher', 'Country', 'OriginalPaperDate', 'RetractionNature']\n",
    "data = data[selected_features]\n",
    "data = pd.get_dummies(data, columns=['Journal', 'Publisher', 'Country', 'OriginalPaperDate'])\n",
    "\n",
    "print(\"Data preprocessed in {:.2f} seconds\".format(time.time() - start_time))\n",
    "\n",
    "# Split the data into features and target\n",
    "X = data.drop(columns=['RetractionNature'])\n",
    "y = data['RetractionNature']\n",
    "\n",
    "# Check the distribution of classes\n",
    "class_distribution = Counter(y)\n",
    "print(\"Class distribution before SMOTE:\", class_distribution)\n",
    "\n",
    "# Apply SMOTE to balance the dataset if there are enough samples per class\n",
    "min_samples_required = 6  # Minimum number of samples required for SMOTE\n",
    "if all(count >= min_samples_required for count in class_distribution.values()):\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    print(\"SMOTE applied.\")\n",
    "else:\n",
    "    X_resampled, y_resampled = X, y\n",
    "    print(\"SMOTE not applied due to insufficient samples in one or more classes.\")\n",
    "\n",
    "# Check the distribution of classes after SMOTE\n",
    "class_distribution_resampled = Counter(y_resampled)\n",
    "print(\"Class distribution after SMOTE:\", class_distribution_resampled)\n",
    "\n",
    "# Split the resampled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Data split into training and testing sets in {:.2f} seconds\".format(time.time() - start_time))\n",
    "\n",
    "\n",
    "rf_model = GridSearchCV(RandomForestClassifier(random_state=42), param_grid={\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None]\n",
    "}, cv=3, n_jobs=-1)\n",
    "\n",
    "# Train Random Forest\n",
    "rf_start_time = time.time()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Scale the data for Logistic Regression and SVM\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize classifiers with hyperparameter tuning\n",
    "classifiers = {\n",
    "    \"Random Forest\": GridSearchCV(RandomForestClassifier(random_state=42), param_grid={\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [10, 20, None]\n",
    "    }, cv=3, n_jobs=-1),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Support Vector Machine\": GridSearchCV(SVC(random_state=42), param_grid={\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf']\n",
    "    }, cv=3, n_jobs=-1),\n",
    "    \"Gradient Boosting\": GridSearchCV(GradientBoostingClassifier(random_state=42), param_grid={\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.01, 0.1]\n",
    "    }, cv=3, n_jobs=-1)\n",
    "}\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "results = {}\n",
    "for name, clf in classifiers.items():\n",
    "    clf_start_time = time.time()\n",
    "    if name in [\"Logistic Regression\", \"Support Vector Machine\"]:\n",
    "        clf.fit(X_train_scaled, y_train)\n",
    "        y_pred = clf.predict(X_test_scaled)\n",
    "    else:\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    clf_end_time = time.time()\n",
    "    clf_total_time = clf_end_time - clf_start_time\n",
    "    results[name] = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Classification Report\": report,\n",
    "        \"Training Time (s)\": clf_total_time\n",
    "    }\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "# Display the results\n",
    "for name, result in results.items():\n",
    "    print(f\"\\nClassifier: {name}\")\n",
    "    print(f\"Accuracy: {result['Accuracy']}\")\n",
    "    print(result[\"Classification Report\"])\n",
    "    print(f\"Training Time: {result['Training Time (s)']:.2f} seconds\")\n",
    "\n",
    "print(\"Total time taken: {:.2f} seconds\".format(total_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92d30c43-ef4c-41d7-8ea7-8fc2bf03fc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('random_forest_model.pkl', 'wb') as rf_file:\n",
    "    pickle.dump(rf_model, rf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43d6bb5-f3b7-4b73-b322-faa3119b9d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
